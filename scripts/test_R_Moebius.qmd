 ---
title: Testing MoEBius
output: html_document
---



## Simulation of an easy data set for Moebius


```{r}
# Load dependencies and source code
source("../code/MoEBIUS-Rpackage/R/F_simulations.R")
source("../code/MoEBIUS-Rpackage/R/MoEBIUS.R")
source("../code/MoEBIUS-Rpackage/R/F_utils.R")


# ------------------------------
# 1. Simulate synthetic data
# ------------------------------
set.seed(123)

# Define parameters
N <- 500     # number of observations
p <- 10      # number of features
K <- 3       # number of row clusters
Q <- 2       # number of column clusters

# Simulate data
data_sim <- simu_CCLBM_supervised(N = N, p = p, K = K, Q = Q)

```

### Representation of the simulated data (3 row clusters and two column clusters)

```{r}
library(ggplot2)
library(plotly)
library(RColorBrewer)

# Extract simulation components
X <- data_sim$X
Z <- data_sim$Z_classif
W <- data_sim$W_classif
y <- as.vector(data_sim$y)

# -----------------------------
# 1. Heatmap of X with ordering
# -----------------------------

# Reorder rows and columns
row_order <- order(Z)
col_order <- order(W[Z[row_order[1]], ])  # W depends on Z[k,]

X_reordered <- X[row_order, col_order]

# Plot heatmap
heatmap(X_reordered,
        Rowv = NA, Colv = NA,
        scale = "none", col = colorRampPalette(brewer.pal(9, "YlGnBu"))(100),
        main = "Reordered Heatmap of X (by Z and W)")

# -----------------------------
# 2. PCA with y as third dimension
# -----------------------------

# Run PCA
pca <- prcomp(X, scale. = TRUE)
pca_df <- data.frame(PC1 = pca$x[,1],
                     PC2 = pca$x[,2],
                     y = y,
                     cluster = factor(Z))

# 3D Scatter plot with y as color
plot_ly(data = pca_df,
        x = ~PC1, y = ~PC2, z = ~y,
        color = ~cluster,
        colors = RColorBrewer::brewer.pal(length(unique(Z)), "Set2"),
        type = 'scatter3d',
        mode = 'markers') %>%
  layout(title = "3D Visualization: PCA(X) + y",
         scene = list(
           xaxis = list(title = 'PC1'),
           yaxis = list(title = 'PC2'),
           zaxis = list(title = 'y')))
```

## Learning set error


```{r}

# Extract predictors and response
X <- data_sim$X
y <- as.vector(data_sim$y)

# ------------------------------
# 2. Fit MoEBIUS model
# ------------------------------
model_fit <- MoEBIUS_reg(
  X = X,
  y = y,
  K_set = K,           # fixed K
  Q_set = Q,           # fixed Q
  iter_max = 2000,       # number of EM iterations
  learning_rate = 7e-2,# optional: slightly higher LR
  Cross_val = FALSE    # disable cross-validation
)

# ------------------------------
# 3. Predict on training data
# ------------------------------
y_pred <- prediction_MoEBIUS_reg(model_fit$best_ELBO, X)

# ------------------------------
# 4. Evaluate model
# ------------------------------
mse <- mean((y - y_pred)^2)
cat("MSE on training data:", mse, "\n")

# Optional: plot predicted vs true
plot(y, y_pred,
     main = "MoEBIUS: Predicted vs True y",
     xlab = "True y", ylab = "Predicted y",
     pch = 19, col = "steelblue")
abline(a = 0, b = 1, col = "red", lwd = 2)

```


```{r}
# --- 1. Simulate Training Data ---
set.seed(123)
K <- 3; Q <- 2; p <- 10; N_train <- 500; N_test <- 700

data <- simu_CCLBM_supervised(N = N_train+N_test, p = p, K = K, Q = Q)
train_index<-sample(1:(N_train+N_test),N_train,replace=FALSE)


X_train <- data$X[train_index,]
y_train <- as.vector(data$y[train_index])

X_test <- data$X[-train_index,]
y_test <- as.vector(data$y[-train_index])

# --- 3. Fit MoEBIUS on Training Data ---
model <- MoEBIUS_reg(
  X = X_train,
  y = y_train,
  K_set = K,
  Q_set = Q,
  learning_rate = 7e-2,
  iter_max = 1000,
  Cross_val = FALSE
)

# --- 4a. Predict on Test Set ---
y_pred_test <- prediction_MoEBIUS_reg(model$best_ELBO, X_test)
# --- 4b. Predict on Training Set ---
y_pred_train <- prediction_MoEBIUS_reg(model$best_ELBO, X_train)

# --- 5b. Compute Train MSE ---
mse_train <- mean((y_train - y_pred_train)^2)
# --- 5c. Compute Train MSE ---
mse_test <- mean((y_test - y_pred_test)^2)

# --- 6. Display Summary Table ---
summary_df <- data.frame(
  N_train = N_train,
  N_test = N_test,
  p = p,
  K = K,
  Q = Q,
  iter_max = model$best_ELBO$iter_max,
  learning_rate = model$best_ELBO$learning_rate,
  MSE_train = round(mse_train, 4),
  MSE_test = round(mse_test, 4)
)

print(summary_df)
```
## Exporting simulated data for comparison with others MoEs



```{r}
write.csv(X_train, "X_train.csv", row.names = FALSE)
write.csv(X_test, "X_test.csv", row.names = FALSE)
write.csv(data.frame(y = y_train), "y_train.csv", row.names = FALSE)
write.csv(data.frame(y = y_test),  "y_test.csv",  row.names = FALSE)
```

